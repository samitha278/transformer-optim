# transformer-optim
Optimize transformer models using adapters (LoRA/PEFT), quantization (4-bit/8-bit), KV caching, and other modern LLM efficiency techniques.
